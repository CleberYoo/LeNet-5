{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 512\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # 총 10개의 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(transforms=[transforms.Resize(size=(227, 227)),\n",
    "                                           transforms.ToTensor()])\n",
    "\n",
    "training_data = datasets.FashionMNIST(root=\"data\", train=True, transform=transform, download=True)\n",
    "validation_data = datasets.FashionMNIST(root=\"data\", train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(dataset=training_data, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(image):\n",
    "    image = image.mean(dim=0)\n",
    "    image = image / 2 + 0.5\n",
    "    np_image = image.numpy()\n",
    "    plt.imshow(X=np_image, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "        \n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0), \n",
    "            # 4D tensor : [number_of_kernels, input_channels, kernel_width, kernel_height] \n",
    "            # = 96x1x11x11\n",
    "            # input size : 1x227x227\n",
    "            # input size 정의 : (N, C, H, W) or (C, H, W)\n",
    "            # W' = (W-F+2P)/S + 1\n",
    "            # 55x55x96 feature map 생성 (55는 (227-11+1)/4)\n",
    "            # 최종적으로 227 -> 55\n",
    "            nn.ReLU(), # 96x55x55\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2) \n",
    "            # 55 -> (55-3+1)/2 = 26.5 = 27\n",
    "            # 96x27x27 feature map 생성\n",
    "\n",
    "        ) \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, 5, 1, 2), # in_channels: 96, out_channels: 256, kernel_size=5x5, stride=1, padding=2\n",
    "            # kernel 수 = 48x5x5 (드롭아웃을 사용했기 때문에 96/2=48) 형태의 256개\n",
    "            # 256x27x27\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2) # 27 -> 13\n",
    "            # 256x13x13\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU() # 13 유지\n",
    "            # 384x13x13\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU() # 13 유지\n",
    "            # 384x13x13\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2) # 13 -> 6\n",
    "            # 256x6x6\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x): # input size = 3x227x227\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out) # 64x4096x1x1\n",
    "        out = out.view(out.size(0), -1) # 64x4096\n",
    "        \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.dropout(out, 0.5)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.dropout(out, 0.5)\n",
    "        out = self.fc3(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet().to(device=device)\n",
    "criterion = F.nll_loss\n",
    "optimizer = optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [512, 96, 55, 55]          11,712\n",
      "              ReLU-2          [512, 96, 55, 55]               0\n",
      "         MaxPool2d-3          [512, 96, 27, 27]               0\n",
      "            Conv2d-4         [512, 256, 27, 27]         614,656\n",
      "              ReLU-5         [512, 256, 27, 27]               0\n",
      "         MaxPool2d-6         [512, 256, 13, 13]               0\n",
      "            Conv2d-7         [512, 384, 13, 13]         885,120\n",
      "              ReLU-8         [512, 384, 13, 13]               0\n",
      "            Conv2d-9         [512, 384, 13, 13]       1,327,488\n",
      "             ReLU-10         [512, 384, 13, 13]               0\n",
      "           Conv2d-11         [512, 256, 13, 13]         884,992\n",
      "             ReLU-12         [512, 256, 13, 13]               0\n",
      "        MaxPool2d-13           [512, 256, 6, 6]               0\n",
      "           Linear-14                [512, 4096]      37,752,832\n",
      "           Linear-15                [512, 4096]      16,781,312\n",
      "           Linear-16                  [512, 10]          40,970\n",
      "================================================================\n",
      "Total params: 58,299,082\n",
      "Trainable params: 58,299,082\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 100.64\n",
      "Forward/backward pass size (MB): 5589.16\n",
      "Params size (MB): 222.39\n",
      "Estimated Total Size (MB): 5912.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model=model, input_size=(1, 227, 227), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # enumberate() : 인덱스와 원소로 이루어진 튜플(tuple)을 만들어줌\n",
    "        target = target.type(torch.LongTensor)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # 항상 backpropagation 하기전에 미분(gradient)을 zero로 만들어주고 시작해야 한다.\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target) # criterion = loss_fn\n",
    "        loss.backward() # Computes the gradient of current tensor w.r.t. graph leaves\n",
    "        optimizer.step() # step() : 파라미터를 업데이트함\n",
    "        if (batch_idx + 1) % 30 == 0:\n",
    "            print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target, reduction='sum').item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)  # -> mean\n",
    "        print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1 [1856/60000 (3%)]\tLoss: 1.598908\n",
      "Train Epoch:1 [3776/60000 (6%)]\tLoss: 1.149229\n",
      "Train Epoch:1 [5696/60000 (9%)]\tLoss: 0.965210\n",
      "Train Epoch:1 [7616/60000 (13%)]\tLoss: 0.910678\n",
      "Train Epoch:1 [9536/60000 (16%)]\tLoss: 0.879698\n",
      "Train Epoch:1 [11456/60000 (19%)]\tLoss: 0.708798\n",
      "Train Epoch:1 [13376/60000 (22%)]\tLoss: 0.476133\n",
      "Train Epoch:1 [15296/60000 (25%)]\tLoss: 0.530906\n",
      "Train Epoch:1 [17216/60000 (29%)]\tLoss: 0.558219\n",
      "Train Epoch:1 [19136/60000 (32%)]\tLoss: 0.667198\n",
      "Train Epoch:1 [21056/60000 (35%)]\tLoss: 0.900905\n",
      "Train Epoch:1 [22976/60000 (38%)]\tLoss: 0.441009\n",
      "Train Epoch:1 [24896/60000 (41%)]\tLoss: 0.517382\n",
      "Train Epoch:1 [26816/60000 (45%)]\tLoss: 0.520099\n",
      "Train Epoch:1 [28736/60000 (48%)]\tLoss: 0.403478\n",
      "Train Epoch:1 [30656/60000 (51%)]\tLoss: 0.470538\n",
      "Train Epoch:1 [32576/60000 (54%)]\tLoss: 0.394310\n",
      "Train Epoch:1 [34496/60000 (57%)]\tLoss: 0.407234\n",
      "Train Epoch:1 [36416/60000 (61%)]\tLoss: 0.329897\n",
      "Train Epoch:1 [38336/60000 (64%)]\tLoss: 0.368430\n",
      "Train Epoch:1 [40256/60000 (67%)]\tLoss: 0.447320\n",
      "Train Epoch:1 [42176/60000 (70%)]\tLoss: 0.280074\n",
      "Train Epoch:1 [44096/60000 (73%)]\tLoss: 0.333438\n",
      "Train Epoch:1 [46016/60000 (77%)]\tLoss: 0.349154\n",
      "Train Epoch:1 [47936/60000 (80%)]\tLoss: 0.397085\n",
      "Train Epoch:1 [49856/60000 (83%)]\tLoss: 0.318546\n",
      "Train Epoch:1 [51776/60000 (86%)]\tLoss: 0.470679\n",
      "Train Epoch:1 [53696/60000 (89%)]\tLoss: 0.260550\n",
      "Train Epoch:1 [55616/60000 (93%)]\tLoss: 0.385125\n",
      "Train Epoch:1 [57536/60000 (96%)]\tLoss: 0.415584\n",
      "Train Epoch:1 [59456/60000 (99%)]\tLoss: 0.385393\n",
      "\n",
      "Test set: Average loss: 0.4054, Accuracy: 8456/10000 (85%)\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train(model, device, training_loader, optimizer, epoch)\n",
    "    test(model, device, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
