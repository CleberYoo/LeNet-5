{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ddc0deed-1112-4fa9-a4b0-f3b9dcaf3cf1",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "## Writing Classic CNN LeNet5 from Scratch in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "13949a7e-0e5b-415f-9918-d6222cfc01f1",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "In this notebook, we would write one of the earliest Convolutional Neural Networks, LeNet5, from scratch in PyTorch. You can read more about it here: http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a4e66000-a4de-4b2c-bcde-13d1c53d6590",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a2de3a5e-c5a0-4d1e-93b4-5da28116b48b",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "Let's start by importing the required libraries and defining some required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "d69990a8-b672-4745-be8e-049eb44b50d8",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# torch.manual_seed(777)\n",
    "# if device == 'cuda':\n",
    "#     torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5971b859-9f8c-405f-b50d-2256fd158dc0",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Downloading and Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9ef7e43a-f2b4-44c1-ac53-9c6dc11f0021",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "We will download the datasets from `torchvision` and load them into PyTorch. We will also apply some transformations, such as resizing the images, converting them to tensors and normalizing them using the mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "ab776b18-1162-4600-9f41-8b39f0921784",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "89ba3973-1533-4e4e-a1d2-0b8653049683",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.Compose([transforms.Resize(size=(32,32)), transforms.ToTensor(), transforms.Normalize(mean=(0.1307,), std=(0.3081,))]), download=False)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.Compose([transforms.Resize(size=(32,32)), transforms.ToTensor(), transforms.Normalize(mean=(0.1325,), std=(0.3105,))]), download=False)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "               \n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "303f069b-9e7d-4d98-94c0-01b0296ce9f2",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### LeNet5 From Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b564c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -9   4  -6  -8   3   5   3   2   4   7]\n",
      " [  3   5  -9  -4   2   3  -3  -5   8   4]\n",
      " [  6  -7   3  -3  -1  -3   2   9   5   3]\n",
      " [ -6  -8  -2   7   1  -3   6   6  -1  -9]\n",
      " [  3   7   2   6   5   0   8   2  -7  -6]\n",
      " [  0  -9   1   0  -8   0   8  -3   8   6]\n",
      " [ -1   5  -1  -3  -9  -3   2  -9   2  -4]\n",
      " [  9   3   4   9   9  -2  -9 -10  -2  -1]\n",
      " [  0  -9  -1   9  -5   6  -7  -3  -1  -5]\n",
      " [  0 -10   9   4   6  -4   9 -10  -8   5]]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_ex = np.random.randint(low=-10, high=10, size=(10, 10))\n",
    "\n",
    "print(arr_ex)\n",
    "print(arr_ex.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "4c996831-653a-45b1-8e24-3ce0aeb0af5c",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "56d28039-81ab-4fab-b8c2-32dcae2b5db4",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "13d47060-cfd3-4bb0-affb-18d198b579d3",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = ConvNeuralNet( num_classes).to(device)\n",
    "\n",
    "#Defining cost and optimizer\n",
    "cost = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "eb3330d1-d3a0-407e-9bb9-dbc723fa5814",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "e778c82d-f08e-479b-86b7-c5484a859cc7",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.0708\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0323\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0495\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0176\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0137\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0092\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0621\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0036\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0042\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0337\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0038\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0048\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0046\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0066\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0058\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0149\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0116\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0150\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0262\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "            #Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        \t# Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \t\t\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c599e80b-312f-4213-b078-5b5da4c028a4",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "1dcae2d8-da84-4042-a391-46461adb5071",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.82 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
